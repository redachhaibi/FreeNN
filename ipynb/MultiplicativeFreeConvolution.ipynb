{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Multiplicative Free Convolution\n",
    "\n",
    "## Goals of this script: \n",
    "- I.   Monte-Carlo for Multiplicative Free Convolutions\n",
    "- II.  Inverting explicit S-transforms\n",
    "- III. Application to FreeNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Monte-Carlo for some explicit multiplicative free convolutions.\n",
    "\n",
    "Recall that the Marchenko-Pastur law is the universal limit for singular values of Gaussian matrices. Following Marchenko and Pastur (1967)\n",
    "$$ \\frac{1}{2 \\pi} \\frac{\\sqrt{(x-l)(r-x)}}{x} dx ,$$\n",
    "where \n",
    "$$r = (1+\\sqrt{c})^2$$\n",
    "$$l = (1-\\sqrt{c})^2$$\n",
    "and $c$ being the scale parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One MP\n",
    "\n",
    "N=1000\n",
    "num_bins=50\n",
    "\n",
    "c = 3 # MP scale parameter\n",
    "r = (1+np.sqrt(c))**2 #Right end\n",
    "l = (1-np.sqrt(c))**2 #Left end\n",
    "\n",
    "G = np.random.normal( size=(N,c*N) )\n",
    "W = G.dot( G.transpose() )\n",
    "W = W/N\n",
    "diag, U = np.linalg.eig(W)\n",
    "\n",
    "# Histogram of singular values\n",
    "fig, ax = plt.subplots()\n",
    "n, bins, patches = ax.hist(diag, num_bins, density=True)\n",
    "y = np.sqrt( (r-bins)*(bins-l) )/(2*np.pi*bins)\n",
    "ax.plot(bins, y, '--', linewidth=4)\n",
    "ax.set_xlabel('Eigenvalues')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of singular values for N={}'.format(N))\n",
    "fig.tight_layout()\n",
    "plt.xlim(0,r+0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple ones\n",
    "scale_params = [3, 0.5, 2]\n",
    "\n",
    "N=1000\n",
    "num_bins=50\n",
    "\n",
    "M = np.identity(N)\n",
    "for c in scale_params:\n",
    "    p, q = M.shape\n",
    "    qq = int(c*q)\n",
    "    G = np.random.normal( size=(q,qq) )/np.sqrt(q+qq)\n",
    "    M = M.dot( G )\n",
    "    W = M.dot( M.transpose() )\n",
    "    diag, U = np.linalg.eig(W)\n",
    "\n",
    "    # Histogram of singular values\n",
    "    fig, ax = plt.subplots()\n",
    "    n, bins, patches = ax.hist(diag, num_bins)\n",
    "    #y = np.sqrt( (r-bins)*(bins-l) )/(2*np.pi*bins)\n",
    "    #ax.plot(bins)\n",
    "    ax.set_xlabel('Eigenvalues')\n",
    "    ax.set_ylabel('Probability density')\n",
    "    ax.set_title(r'Histogram of singular values for N={}'.format(N))\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Inverting explicit S-transforms\n",
    "Here we consider the $S$-transforms of Marchenko-Pastur distributions, which are of the form:\n",
    "$$ S_{W_l}(z) = \\frac{1}{\\sigma_l} \\frac{1}{1+\\lambda_l z} \\ ,$$\n",
    "where the $\\lambda_i$ are the scale pameters and $\\sigma_l^2$ are the variances. For simplicity, we assume for now $\\sigma_l^2=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from freenn.core import newton, adaptative\n",
    "\n",
    "# Array of \\lambda_l's\n",
    "scale_params = [3, 1, 0.5]\n",
    "# Array of \\Lambda_l / \\lambda_l used for scaling z (Check error in paper!)\n",
    "w_scaling    = np.cumprod(scale_params)/scale_params\n",
    "\n",
    "# Compute coefficients of M_inverse (numerator and denominator)\n",
    "# Conventions:\n",
    "#   - Coefficients are numpy arrays\n",
    "#   - Highest degree comes first\n",
    "#\n",
    "# Of numerator of M_inverse\n",
    "roots         = np.append(-1, -1/w_scaling)\n",
    "leading_coeff = np.prod(w_scaling)\n",
    "coeff_num     = np.poly( roots ) * leading_coeff\n",
    "# Of denominator of M_inverse = w\n",
    "coeff_den     = np.array( [1, 0] )\n",
    "\n",
    "wrapper = newton.Polynomial_Kantorovich_Wrapper( coeff_num, coeff_den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Newton-Raphson iterations\n",
    "\n",
    "Important formulae\n",
    "$$ m = zg - 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for a value in basin of attraction\n",
    "j = complex(0,1)\n",
    "z = 1+ j*3\n",
    "print(\"z: \", z)\n",
    "m = newton.newton_raphson   ( z, function_wrapper=wrapper )\n",
    "g = newton.newton_raphson_ZG( z, function_wrapper = wrapper)\n",
    "print(\"M(z)         = \", m )\n",
    "print(\"G(z)         = \", g )\n",
    "print(\"M_inverse(m) = \", wrapper.phi(m)   )\n",
    "print(\"Error        = \", abs(z-wrapper.phi(m)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Kantorovich criterion for basins of attraction\n",
    "z = complex(1,10)\n",
    "print( newton.is_in_basin_ZG(z, 1/z, function_wrapper = wrapper, debug=True ) )\n",
    "z = complex(1,5)\n",
    "print( newton.is_in_basin_ZG(z, 1/z, function_wrapper = wrapper, debug=True ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "j       = complex(0,1)\n",
    "t       = 1\n",
    "debug   = False\n",
    "z_array = 1+ j*np.array([ 1, 0.1, 1e-5, 1e-8, 1e-10])\n",
    "proxy   = None\n",
    "for z in z_array:\n",
    "    print(\"z: \", z)\n",
    "    adaptative.reset_counters()\n",
    "    g = adaptative.compute_G_adaptative( z, function_wrapper = wrapper, proxy=proxy, debug=False)\n",
    "    proxy = (z, g)\n",
    "    print(\"G(z)  = \", g )\n",
    "    z_check = wrapper.phi(z*g-1)\n",
    "    print(\"Error = \", abs(z_check-z) )\n",
    "    print(\"Number of calls to NR: \", adaptative.call_counter_NR)\n",
    "    print(\"Number of calls to attraction basin test: \", adaptative.call_counter_failed_basin)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computation of the measure (multiple passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#N: Space mesh\n",
    "N=100\n",
    "a=-2\n",
    "b=10\n",
    "\n",
    "#Init\n",
    "space_grid = np.linspace(a, b, N)\n",
    "dx = (b-a)/N\n",
    "\n",
    "#Multiple passes for the number of iterations\n",
    "imaginary_parts = [1.0, 0.1, 0.01, 1e-4, 1e-8]\n",
    "densities       = []\n",
    "hilbert_transf  = []\n",
    "pass_counter    = 0\n",
    "iter_count      = [ [] for i in space_grid ]\n",
    "errors1         = [ [] for i in space_grid ]\n",
    "errors2         = [ [] for i in space_grid ]\n",
    "choices         = [ [] for i in space_grid ]\n",
    "\n",
    "j       = complex(0,1)\n",
    "fig = plt.figure( figsize = (12,7) )\n",
    "ax = fig.add_subplot( 111 )\n",
    "y_proxy = None\n",
    "guess   = None\n",
    "G       = np.array( space_grid + complex(0,1) )\n",
    "for y in imaginary_parts:\n",
    "    start = time.time()\n",
    "    adaptative.reset_counters()\n",
    "    # Compute\n",
    "    z = np.array( space_grid + y*complex(0,1) )\n",
    "    for i in range(N):\n",
    "        if y_proxy is None:\n",
    "            G[i] = adaptative.compute_G_adaptative(z[i], function_wrapper = wrapper, proxy=None)\n",
    "        else:\n",
    "            guess = (z[i].real+j*y_proxy, G[i])\n",
    "            G[i] = adaptative.compute_G_adaptative(z[i], function_wrapper = wrapper, proxy=guess)\n",
    "    # Statistics\n",
    "    pass_counter += 1\n",
    "    timing        = time.time() - start\n",
    "    print ('Pass [{}/{}], Duration: {:.1f} ms' \n",
    "           .format(pass_counter, len(imaginary_parts), 1000*timing))\n",
    "    print(\"Number of calls to subroutine:\")\n",
    "    print(\"'Newton-Raphson'  :\", adaptative.call_counter_NR)\n",
    "    print(\"'Attraction basin':\", adaptative.call_counter_failed_basin)\n",
    "    print(\"\")\n",
    "    # Plot\n",
    "    ax.plot(space_grid, -np.imag(G)/np.pi, '--', label=\"y=%.5f\"%y)\n",
    "    ax.set(xlabel='Space (x)', ylabel='Value',\n",
    "           title='Density')\n",
    "    ax.grid()\n",
    "    #\n",
    "    y_proxy = y\n",
    "plt.ylim(0,0.2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
